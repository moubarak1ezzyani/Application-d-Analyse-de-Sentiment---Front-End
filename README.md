````markdown
# ğŸ¨ Interface d'Analyse de Sentiment (Next.js Client)

Ce dÃ©pÃ´t contient le code source de l'interface utilisateur (Frontend) pour le microservice d'analyse de sentiment. DÃ©veloppÃ© avec **Next.js (React)**, il offre une interface propre et rÃ©active pour interagir avec notre API Backend sÃ©curisÃ©e.

Il permet aux utilisateurs de s'authentifier et de tester le modÃ¨le d'IA `nlptown/bert-base-multilingual-uncased-sentiment` en temps rÃ©el.

-----

## ğŸš€ FonctionnalitÃ©s ClÃ©s

* **Authentification SÃ©curisÃ©e :** Formulaire de connexion communiquant avec l'endpoint `/login` du Backend.
* **Gestion de Session :** Stockage sÃ©curisÃ© du JWT (JSON Web Token) dans le `localStorage` du navigateur.
* **Analyse en Temps RÃ©el :** Envoi de texte Ã  analyser vers l'endpoint sÃ©curisÃ© `/predict`.
* **Visualisation des RÃ©sultats :** Affichage clair du sentiment (Positif, NÃ©gatif, Neutre) et du score de confiance (1 Ã  5 Ã©toiles).
* **Gestion des Ã‰tats :** Feedback visuel pour les Ã©tats de chargement (`loading`), de succÃ¨s et d'erreur.

-----

## ğŸ› ï¸ Stack Technique

* **Framework :** [Next.js](https://nextjs.org/) (React)
* **Style :** CSS Modules / Tailwind CSS (selon votre choix)
* **RequÃªtes HTTP :** Fetch API ou Axios
* **Conteneurisation :** Docker

-----

## ğŸ“¦ Installation et DÃ©marrage Rapide

### PrÃ©requis
* Node.js (v16 ou supÃ©rieur)
* Le Backend API doit Ãªtre lancÃ© (voir le repo Backend).

### 1. Configuration de l'Environnement
CrÃ©ez un fichier `.env.local` Ã  la racine du projet pour indiquer l'adresse de votre Backend :

```env
# URL de votre API Backend (ex: FastAPI running on port 8000)
NEXT_PUBLIC_API_URL="http://localhost:8000"
````

### 2\. Installation des dÃ©pendances

```bash
npm install
# ou
yarn install
```

### 3\. Lancer le serveur de dÃ©veloppement

```bash
npm run dev
# ou
yarn dev
```

L'application sera accessible Ã  l'adresse : `http://localhost:3000`

-----

## ğŸ³ DÃ©marrage avec Docker

Pour lancer uniquement le conteneur Frontend :

```bash
# Construire l'image
docker build -t sentiment-frontend .

# Lancer le conteneur (port 3000)
docker run -p 3000:3000 sentiment-frontend
```

*Note : Assurez-vous que le conteneur peut communiquer avec le Backend (configuration rÃ©seau Docker).*

-----

## ğŸ”„ Workflow Utilisateur

1.  **Page `/login` :** L'utilisateur saisit ses identifiants. En cas de succÃ¨s, le token est sauvegardÃ©.
2.  **Redirection :** L'utilisateur est redirigÃ© vers la page d'analyse.
3.  **Page `/sentiment` :**
      * L'utilisateur tape un avis client.
      * Le Front envoie la requÃªte avec le header `Authorization: Bearer <token>`.
      * Le rÃ©sultat de l'IA s'affiche instantanÃ©ment.

-----

## ğŸ¤ Contribution

Les Pull Requests sont les bienvenues. Pour des changements majeurs, veuillez ouvrir une issue d'abord pour discuter de ce que vous souhaitez changer.

````

---

### ğŸ“‚ 2. Contenu pour le Repo `BACKEND` (FastAPI)
*Ce README est purement technique. Il s'adresse aux dÃ©veloppeurs Backend/DevOps et dÃ©taille l'API, la sÃ©curitÃ©, la configuration Docker et les tests.*

```markdown
# âš™ï¸ API Microservice d'Analyse de Sentiment (FastAPI)

Ce dÃ©pÃ´t hÃ©berge le code Backend du projet. C'est une API REST performante construite avec **FastAPI** qui sert de passerelle sÃ©curisÃ©e entre le Frontend et le modÃ¨le d'IA hÃ©bergÃ© sur **Hugging Face**.

Elle gÃ¨re l'authentification, la validation des donnÃ©es et la logique mÃ©tier de transformation des scores de sentiment.

-----

## ğŸ¯ Objectifs Techniques

* **SÃ©curitÃ© AvancÃ©e :** ImplÃ©mentation d'un systÃ¨me d'authentification robuste via **JWT (JSON Web Token)**.
* **IntÃ©gration IA :** Consommation de l'API Inference Hugging Face (`nlptown/bert-base-multilingual-uncased-sentiment`).
* **Architecture Propre :** SÃ©paration des prÃ©occupations (Routes, Auth, Services).
* **Documentation Auto :** Swagger UI intÃ©grÃ© via FastAPI.

-----

## ğŸ› ï¸ Stack Technique

| Technologie | Usage |
| :--- | :--- |
| **Python 3.9+** | Langage principal. |
| **FastAPI** | Framework Web asynchrone haute performance. |
| **Uvicorn** | Serveur ASGI. |
| **PyJWT** | Gestion de l'encodage/dÃ©codage des tokens. |
| **Requests** | Appels HTTP vers Hugging Face. |
| **Docker** | Conteneurisation du service. |
| **Pytest** | Tests unitaires et d'intÃ©gration. |

-----

## ğŸ”Œ Endpoints de l'API

| MÃ©thode | Endpoint | AccÃ¨s | Description |
| :--- | :--- | :--- | :--- |
| `POST` | **/login** | ğŸ”“ Public | Authentifie l'utilisateur et dÃ©livre un Token JWT. |
| `POST` | **/predict** | ğŸ”’ **SÃ©curisÃ©** | Analyse le sentiment d'un texte via l'IA. Requiert un Header `Authorization`. |
| `GET` | **/docs** | ğŸ”“ Public | Documentation interactive (Swagger UI). |

### Logique de Transformation (Business Logic)
L'API reÃ§oit un score de 1 Ã  5 de l'IA et le convertit selon cette rÃ¨gle mÃ©tier :
* **1-2 Ã©toiles** â” NÃ©gatif ğŸ”´
* **3 Ã©toiles** â” Neutre ğŸŸ¡
* **4-5 Ã©toiles** â” Positif ğŸŸ¢

-----

## ğŸ”‘ Configuration (.env)

**ImpÃ©ratif :** CrÃ©ez un fichier `.env` Ã  la racine pour stocker vos secrets. Ne commitez jamais ce fichier.

```env
# ClÃ© API Hugging Face (Obtenue sur hf.co/settings/tokens)
HF_API_KEY="hf_xxxxxxxxxxxxxxxxxxxx"

# SÃ©curitÃ© JWT
SECRET_KEY="votre_clÃ©_secrÃ¨te_super_longue_et_alÃ©atoire"
ALGORITHM="HS256"
ACCESS_TOKEN_EXPIRE_MINUTES=30
````

-----

## ğŸš€ Installation et Lancement

### A. Via Python (Local)

1.  **Cloner et installer les dÃ©pendances :**
    ```bash
    pip install -r requirements.txt
    ```
2.  **Lancer le serveur :**
    ```bash
    uvicorn main:app --reload
    ```
    *L'API est accessible sur `http://localhost:8000`*

### B. Via Docker (RecommandÃ©)

1.  **Construire l'image :**
    ```bash
    docker build -t sentiment-backend .
    ```
2.  **Lancer le conteneur :**
    ```bash
    docker run -p 8000:8000 --env-file .env sentiment-backend
    ```

-----

## ğŸ§ª Tests et QualitÃ©

### Tests Unitaires (Pytest)

Le projet inclut une suite de tests pour valider la sÃ©curitÃ© et la logique.

```bash
pytest
```

### Tests Manuels (Postman/cURL)

Exemple de test sÃ©curisÃ© :

```bash
# 1. Login (RÃ©cupÃ©rer le token)
curl -X POST "http://localhost:8000/login" ...

# 2. Predict (Utiliser le token)
curl -X POST "http://localhost:8000/predict" \
     -H "Authorization: Bearer <VOTRE_TOKEN>" \
     -d '{"text": "Ce produit est incroyable !"}'
```

-----

## âš ï¸ Limitations Connues

  * **DÃ©pendance Externe :** La disponibilitÃ© du service `/predict` dÃ©pend de l'Ã©tat des serveurs de Hugging Face.
  * **Rate Limiting :** L'API Hugging Face gratuite impose des limites de requÃªtes par heure.

<!-- end list -->

```
```
